{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-13T11:55:42.765880Z","iopub.execute_input":"2023-07-13T11:55:42.766155Z","iopub.status.idle":"2023-07-13T11:56:06.055507Z","shell.execute_reply.started":"2023-07-13T11:55:42.766129Z","shell.execute_reply":"2023-07-13T11:56:06.054535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install numpy\n!pip install tensorflow","metadata":{"execution":{"iopub.status.busy":"2023-07-13T11:56:06.057339Z","iopub.execute_input":"2023-07-13T11:56:06.058330Z","iopub.status.idle":"2023-07-13T11:56:29.909773Z","shell.execute_reply.started":"2023-07-13T11:56:06.058294Z","shell.execute_reply":"2023-07-13T11:56:29.908547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-07-13T11:56:29.913328Z","iopub.execute_input":"2023-07-13T11:56:29.913681Z","iopub.status.idle":"2023-07-13T11:56:37.682614Z","shell.execute_reply.started":"2023-07-13T11:56:29.913648Z","shell.execute_reply":"2023-07-13T11:56:37.681241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [224, 224]\n","metadata":{"execution":{"iopub.status.busy":"2023-07-13T11:56:37.690576Z","iopub.execute_input":"2023-07-13T11:56:37.691623Z","iopub.status.idle":"2023-07-13T11:56:37.702230Z","shell.execute_reply.started":"2023-07-13T11:56:37.691571Z","shell.execute_reply":"2023-07-13T11:56:37.700985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_directory='../input/100-bird-species/train'\ntest_directory='../input/100-bird-species/test'\nval_directory='../input/100-bird-species/valid'","metadata":{"execution":{"iopub.status.busy":"2023-07-13T11:56:37.708354Z","iopub.execute_input":"2023-07-13T11:56:37.708797Z","iopub.status.idle":"2023-07-13T11:56:37.719176Z","shell.execute_reply.started":"2023-07-13T11:56:37.708753Z","shell.execute_reply":"2023-07-13T11:56:37.717986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add preprocessing layer to the front of VGG\nvgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n# don't train existing weights\nfor layer in vgg.layers:\n  layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-07-13T11:56:37.722439Z","iopub.execute_input":"2023-07-13T11:56:37.723415Z","iopub.status.idle":"2023-07-13T11:56:41.646776Z","shell.execute_reply.started":"2023-07-13T11:56:37.723368Z","shell.execute_reply":"2023-07-13T11:56:41.645710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # useful for getting number of classes\nfolders = glob('../input/100-bird-species/train/*')\nlen(folders)","metadata":{"execution":{"iopub.status.busy":"2023-07-13T11:56:41.648054Z","iopub.execute_input":"2023-07-13T11:56:41.648416Z","iopub.status.idle":"2023-07-13T11:56:41.664742Z","shell.execute_reply.started":"2023-07-13T11:56:41.648382Z","shell.execute_reply":"2023-07-13T11:56:41.663727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# our layers - you can add more if you want\nx = Flatten()(vgg.output)\n# x = Dense(1000, activation='relu')(x)\nprediction = Dense(len(folders), activation='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2023-07-13T11:56:41.666304Z","iopub.execute_input":"2023-07-13T11:56:41.666953Z","iopub.status.idle":"2023-07-13T11:56:41.692702Z","shell.execute_reply.started":"2023-07-13T11:56:41.666813Z","shell.execute_reply":"2023-07-13T11:56:41.691809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a model object\nmodel = Model(inputs=vgg.input, outputs=prediction)\n\n# view the structure of the model\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-13T11:56:41.694530Z","iopub.execute_input":"2023-07-13T11:56:41.695190Z","iopub.status.idle":"2023-07-13T11:56:41.745581Z","shell.execute_reply.started":"2023-07-13T11:56:41.695157Z","shell.execute_reply":"2023-07-13T11:56:41.744890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import metrics\n\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy', metrics.Precision(), metrics.Recall(), metrics.AUC()]\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-13T11:56:41.748547Z","iopub.execute_input":"2023-07-13T11:56:41.750072Z","iopub.status.idle":"2023-07-13T11:56:42.075883Z","shell.execute_reply.started":"2023-07-13T11:56:41.750045Z","shell.execute_reply":"2023-07-13T11:56:42.074845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)\n\ntraining_set = train_datagen.flow_from_directory(train_directory,\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')\n\ntest_set = test_datagen.flow_from_directory(test_directory,\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')","metadata":{"execution":{"iopub.status.busy":"2023-07-13T11:56:42.077362Z","iopub.execute_input":"2023-07-13T11:56:42.077711Z","iopub.status.idle":"2023-07-13T11:56:47.747665Z","shell.execute_reply.started":"2023-07-13T11:56:42.077676Z","shell.execute_reply":"2023-07-13T11:56:47.746730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(training_set))\nprint(len(test_set))\n","metadata":{"execution":{"iopub.status.busy":"2023-07-13T11:56:47.749283Z","iopub.execute_input":"2023-07-13T11:56:47.749637Z","iopub.status.idle":"2023-07-13T11:56:47.755788Z","shell.execute_reply.started":"2023-07-13T11:56:47.749602Z","shell.execute_reply":"2023-07-13T11:56:47.754819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = model.fit_generator(\n  training_set,\n  validation_data=test_set,\n  epochs=50,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set)\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:35:42.667323Z","iopub.execute_input":"2023-07-13T15:35:42.667692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting accuracy and validation accuracy\nplt.plot(r.history['accuracy'], label='Train Accuracy')\nplt.plot(r.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('Birds_Species.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n\nmodel1 = load_model('./Birds_Species.h5',compile=False) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lab = training_set.class_indices\nlab={k:v for v,k in lab.items()}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def output(location):\n    img=load_img(location,target_size=(224,224,3))\n    img=img_to_array(img)\n    img=img/255\n    img=np.expand_dims(img,[0])\n    answer=model1.predict(img)\n    y_class = answer.argmax(axis=-1)\n    y = \" \".join(str(x) for x in y_class)\n    y = int(y)\n    res = lab[y]\n    return res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img='../input/100-bird-species/valid/BARN OWL/2.jpg'\npic=load_img('../input/100-bird-species/valid/BARN OWL/2.jpg',target_size=(224,224,3))\nplt.imshow(pic)\noutput(img)","metadata":{},"execution_count":null,"outputs":[]}]}